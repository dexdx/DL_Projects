{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87f3aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "226bdc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8086a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = dlc_practical_prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56be990d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weight-sharing \"Siamese\" LeNet\n",
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        \n",
    "        self.LeNet1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_bro(self, x):\n",
    "        x = self.LeNet1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_bro(x1)\n",
    "        x2 = self.forward_bro(x2)\n",
    "        x3 = x2 - x1\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7517444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight-sharing \"Siamese\" LeNet\n",
    "class Siamese_no_sharing(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese_no_sharing, self).__init__()\n",
    "        \n",
    "        self.LeNet1_x1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2_x1 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )        \n",
    "        \n",
    "        self.LeNet1_x2 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2_x2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_x2(self, x):\n",
    "        x = self.LeNet1_x2(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2_x2(x)\n",
    "        return x  \n",
    "        \n",
    "        \n",
    "    def forward_x1(self, x):\n",
    "        x = self.LeNet1_x1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2_x1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_x1(x1)\n",
    "        x2 = self.forward_x2(x2)\n",
    "        x3 = x2 - x1\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "373574ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# control convolutions' dimensions\n",
    "x1 = train_input.narrow(0,0,100)\n",
    "x1 = x1[:,0].view(100,1,14,14)\n",
    "weight1 = torch.empty(16,1,5,5).normal_()\n",
    "bias1 = torch.empty(16).normal_()\n",
    "x1 = F.conv2d(x1, weight1, bias1)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "weight2 = torch.empty(32,16,2,2).normal_()\n",
    "bias2 = torch.empty(32).normal_()\n",
    "x1 = F.conv2d(x1, weight2, bias2)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "x1 = x1.view(-1,1,128)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fe83bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, batch_size, nb_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            imgs = train_input.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "            loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "            acc_loss += loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf83dc99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.959452927112579\n",
      "1 6.8142993450164795\n",
      "2 6.8592864871025085\n",
      "3 6.8395684361457825\n",
      "4 6.808608770370483\n",
      "5 6.862435340881348\n",
      "6 6.588079035282135\n",
      "7 6.56357616186142\n",
      "8 6.194024980068207\n",
      "9 5.865689426660538\n",
      "10 5.478522688150406\n",
      "11 5.089710146188736\n",
      "12 5.009523510932922\n",
      "13 4.836585372686386\n",
      "14 4.346704363822937\n",
      "15 3.979830712080002\n",
      "16 3.9764696061611176\n",
      "17 4.40175786614418\n",
      "18 3.3094355165958405\n",
      "19 3.8473612517118454\n",
      "20 3.449337124824524\n",
      "21 2.778465613722801\n",
      "22 2.942721650004387\n",
      "23 2.968912735581398\n",
      "24 3.4355210065841675\n"
     ]
    }
   ],
   "source": [
    "#model = Siamese()\n",
    "model = Siamese_no_sharing()\n",
    "train_model(model, train_input, train_target, 100, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a56fb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_data, target_data, batch_size):\n",
    "    nb_errors = 0\n",
    "    \n",
    "    for b in range(0, input_data.size(0), batch_size):\n",
    "            imgs = input_data.narrow(0, b, batch_size)\n",
    "            target = target_data.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "            pred = output.max(1)[1]\n",
    "            nb_errors += (pred-target).abs().sum().item()\n",
    "    \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17db12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = compute_nb_errors(model, train_input, train_target, 100)\n",
    "test_errors = compute_nb_errors(model, test_input, test_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c42bd8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_input.size(0) - train_errors)/train_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423067e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_input.size(0) - test_errors)/test_input.size(0)\n",
    "# crazy overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cb41634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_input.size(0) - test_errors)/test_input.size(0)\n",
    "#For no sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fe7747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_input.size(0) - train_errors)/train_input.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f12a36",
   "metadata": {},
   "source": [
    "# AUXILLARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3be4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = dlc_practical_prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da18601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight-sharing \"Siamese\" LeNet\n",
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        \n",
    "        self.LeNet1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        self.AuxLayer = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,10)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_bro(self, x):\n",
    "        x = self.LeNet1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_bro(x1)\n",
    "        x2 = self.forward_bro(x2)\n",
    "        x3 = x2 - x1\n",
    "        x2 = self.AuxLayer(x2)\n",
    "        x2 = self.AuxLayer(x2)\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e97ff82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 128])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# control convolutions' dimensions\n",
    "x1 = train_input.narrow(0,0,100)\n",
    "x1 = x1[:,0].view(100,1,14,14)\n",
    "weight1 = torch.empty(16,1,5,5).normal_()\n",
    "bias1 = torch.empty(16).normal_()\n",
    "x1 = F.conv2d(x1, weight1, bias1)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "weight2 = torch.empty(32,16,2,2).normal_()\n",
    "bias2 = torch.empty(32).normal_()\n",
    "x1 = F.conv2d(x1, weight2, bias2)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "x1 = x1.view(-1,1,128)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dee7e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79d2f1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 0, 8, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes.narrow(0, 0, 5)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7618605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 7],\n",
       "        [7, 0],\n",
       "        [0, 3],\n",
       "        ...,\n",
       "        [2, 6],\n",
       "        [1, 2],\n",
       "        [9, 2]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f824c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target,train_classes, batch_size, nb_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    aux_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            imgs = train_input.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            x1_pred, x2_pred , output = model(imgs1, imgs2)\n",
    "            print(\"batch\" , batch_size)\n",
    "            print(\"x1_shape: \", x2_pred.shape)\n",
    "            x1_pred = x1_pred.view(batch_size, -1)\n",
    "            x2_pred = x2_pred.view(batch_size, -1)\n",
    "            output = output.view(batch_size, -1)\n",
    "            loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "            #print(\"x1_shape: \", x1_pred.shape)\n",
    "            print(\"classes_shape: \", train_classes.narrow(0, b, batch_size)[:,0].shape)\n",
    "            loss_aux1 = aux_criterion(x1_pred,train_classes.narrow(0, b, batch_size)[:,0])\n",
    "            loss_aux1 += aux_criterion(x2_pred,train_classes.narrow(0, b, batch_size)[:,1])\n",
    "            loss = loss + loss_aux1\n",
    "            acc_loss += loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1baccf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "0 11090.51515007019\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "1 75.68332624435425\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "2 75.01652574539185\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "3 74.35206842422485\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "4 73.79076433181763\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "5 73.2761058807373\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "6 72.22995948791504\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "7 70.83448076248169\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "8 69.93021726608276\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "9 69.47552490234375\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "10 69.29026317596436\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "11 69.22440910339355\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "12 69.20350694656372\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "13 69.19719123840332\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "14 69.19536256790161\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "15 69.1948766708374\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "16 69.19472789764404\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "17 69.1946668624878\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "18 69.19463348388672\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "19 69.19463682174683\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "20 69.19461679458618\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "21 69.1946120262146\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "22 69.19461488723755\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "23 69.1946177482605\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "batch 100\n",
      "x1_shape:  torch.Size([100, 1, 32])\n",
      "classes_shape:  torch.Size([100])\n",
      "24 69.19459962844849\n"
     ]
    }
   ],
   "source": [
    "model = Siamese()\n",
    "train_model(model, train_input, train_target,train_classes, 100, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0de5f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_data, target_data, batch_size):\n",
    "    nb_errors = 0\n",
    "    \n",
    "    for b in range(0, input_data.size(0), batch_size):\n",
    "            imgs = input_data.narrow(0, b, batch_size)\n",
    "            target = target_data.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            _,_, output = model(imgs1, imgs2)\n",
    "            output = output.view(batch_size, -1)\n",
    "            pred = output.max(1)[1]\n",
    "            nb_errors += (pred-target).abs().sum().item()\n",
    "    \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "383b0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = compute_nb_errors(model, train_input, train_target, 100)\n",
    "test_errors = compute_nb_errors(model, test_input, test_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f09dce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.543\n",
      "test acc: 0.574\n"
     ]
    }
   ],
   "source": [
    "print(\"train acc:\" , (train_input.size(0) - train_errors)/train_input.size(0))\n",
    "print(\"test acc:\" , (test_input.size(0) - test_errors)/test_input.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
