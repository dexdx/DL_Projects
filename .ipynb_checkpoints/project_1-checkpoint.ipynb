{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "constant-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FCC, Siamese, Siamese_no_sharing, Siamese_ws_auxilary\n",
    "import dlc_practical_prologue\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modified-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = dlc_practical_prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "developing-liberal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weight-sharing \"Siamese\" LeNet\n",
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        \n",
    "        self.LeNet1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_bro(self, x):\n",
    "        x = self.LeNet1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_bro(x1)\n",
    "        x2 = self.forward_bro(x2)\n",
    "        x3 = x2 - x1\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "destroyed-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_no_sharing(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese_no_sharing, self).__init__()\n",
    "        \n",
    "        self.LeNet1_x1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2_x1 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )        \n",
    "        \n",
    "        self.LeNet1_x2 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2_x2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_x2(self, x):\n",
    "        x = self.LeNet1_x2(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2_x2(x)\n",
    "        return x  \n",
    "        \n",
    "        \n",
    "    def forward_x1(self, x):\n",
    "        x = self.LeNet1_x1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2_x1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_x1(x1)\n",
    "        x2 = self.forward_x2(x2)\n",
    "        x3 = x2 - x1\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dirty-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes = None, batch_size, nb_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            imgs = train_input.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            if train_classes==None:\n",
    "                output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "                loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "            else:\n",
    "                x1_pred, x2_pred , output = model(imgs1, imgs2)\n",
    "                x1_pred = x1_pred.view(batch_size, -1)\n",
    "                x2_pred = x2_pred.view(batch_size, -1)\n",
    "                output = output.view(batch_size, -1)\n",
    "                loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "                loss_aux1 = aux_criterion(x1_pred,train_classes.narrow(0, b, batch_size)[:,0])\n",
    "                loss_aux1 += aux_criterion(x2_pred,train_classes.narrow(0, b, batch_size)[:,1])\n",
    "                loss = loss + loss_aux1\n",
    "            \n",
    "            acc_loss += loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educational-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_data, target_data, batch_size):\n",
    "    nb_errors = 0\n",
    "    \n",
    "    for b in range(0, input_data.size(0), batch_size):\n",
    "            imgs = input_data.narrow(0, b, batch_size)\n",
    "            target = target_data.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "            pred = output.max(1)[1]\n",
    "            nb_errors += (pred-target).abs().sum().item()\n",
    "    \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rates(model, input_data, target_data, class_data=None, batch_size, rounds):\n",
    "    error_rates = torch.empty(rounds)\n",
    "    for r in trange(rounds):\n",
    "        model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "expressed-pizza",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:39<00:00,  3.92s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rates_ws = torch.empty(10)\n",
    "for r in trange(10):\n",
    "    model = Siamese()\n",
    "    train_model(model, train_input, train_target, 100, 25)\n",
    "    error_rates_ws[r] = compute_nb_errors(model, test_input, test_target, 100)/test_input.size(0)\n",
    "error_rates_ws = torch.tensor(error_rates_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "tutorial-physiology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:38<00:00,  3.90s/it]\n"
     ]
    }
   ],
   "source": [
    "error_rates_nows = torch.empty(10)\n",
    "for r in trange(10):\n",
    "    model = Siamese_no_sharing()\n",
    "    train_model(model, train_input, train_target, 100, 25)\n",
    "    error_rates_nows[r] = compute_nb_errors(model, test_input, test_target, 100)/test_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "optical-italic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-7ddd287d5beb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSiamese_ws_auxilary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\EPFL\\EE-559\\DL_Projects\\models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSiamese_ws_auxilary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         self.LeNet1 = nn.Sequential(\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = Siamese_ws_auxilary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
