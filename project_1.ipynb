{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116762ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FCC, Siamese, Siamese_no_sharing\n",
    "import dlc_practical_prologue\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "from utils import Proj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa2b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = dlc_practical_prologue.generate_pair_sets(1000)\n",
    "\n",
    "train_data = (train_input, train_target, train_classes)\n",
    "test_data = (test_input, test_target, test_classes)\n",
    "\n",
    "# INstantiate models\n",
    "models = (FCC(), FCC(), Siamese_no_sharing(), Siamese_no_sharing(), Siamese(), Siamese())\n",
    "models[1].setAuxillary()\n",
    "models[3].setAuxillary()\n",
    "models[5].setAuxillary()\n",
    "model_names = ('FCC' , 'FCC w Auxiliary Loss','Siamese (no weight sharing)', 'Siamese (no weight sharing and Auxiliary loss)', 'Siamese (weight sharing)', 'Siamese (weight sharing and Auxiliary Loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(models, model_names, train_data, test_data, batch_size=100, rounds=10, epochs=25):\n",
    "    '''\n",
    "    - train and test_date should be complete (train_input, train_target, train_classes)\n",
    "    - model_names are strings, that should contain the word Auxiliary\n",
    "    '''\n",
    "    # Unpack data\n",
    "    train_input, train_target, train_classes = train_data\n",
    "    test_input, test_target, test_classes = test_data\n",
    "    # Initialize err rates arrays\n",
    "    train_error_rates = torch.empty(rounds)\n",
    "    test_error_rates = torch.empty(rounds)\n",
    "    \n",
    "    # Iterate models\n",
    "    for model, name in zip(models, model_names):\n",
    "        print(f'Training model {name}:')\n",
    "        # Iterate over r to get average\n",
    "        for r in trange(rounds):\n",
    "            # Call train_model with the correct parameters\n",
    "            if 'Aux' in name:\n",
    "                Proj1.train_model(model, train_input, train_target, batch_size, epochs, train_classes)\n",
    "            else:\n",
    "                Proj1.train_model(model, train_input, train_target, batch_size, epochs, train_classes=None)\n",
    "            # Get error on train and test set\n",
    "            train_error_rates[r] = Proj1.compute_nb_errors(model, train_input, train_target, batch_size)/train_input.size(0)\n",
    "            test_error_rates[r] = Proj1.compute_nb_errors(model, test_input, test_target, batch_size)/test_input.size(0)\n",
    "            \n",
    "        #print(f'For the model {name}, the train average error rate is {train_error_rates.mean()} and the test average error rate {test_error_rates.mean()}\\n')\n",
    "        print('For the model {}, the train average error rate is {:.3}% and the test average error rate is {:.3}%.\\n'\n",
    "              .format(name, 100*train_error_rates.mean(), 100*test_error_rates.mean()))\n",
    "#     return error_rates\n",
    "\n",
    "\n",
    "# def error_rates(model, input_data, target_data, batch_size=100, rounds=10, epochs=25, target_classes=None):\n",
    "#     error_rates = torch.empty(rounds)\n",
    "#     for r in trange(rounds):\n",
    "#         train_model(model, train_input, train_target, 100, 25, target_classes)\n",
    "#         error_rates[r] = compute_nb_errors(model, test_input, test_target, 100)/test_input.size(0)\n",
    "#     return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81297f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model FCC:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model FCC, the train average error rate is 0.2% and the test average error rate is 14.4%.\n",
      "\n",
      "Training model FCC w Auxiliary Loss:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.69s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model FCC w Auxiliary Loss, the train average error rate is 1.4% and the test average error rate is 10.0%.\n",
      "\n",
      "Training model Siamese (no weight sharing):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model Siamese (no weight sharing), the train average error rate is 15.9% and the test average error rate is 21.0%.\n",
      "\n",
      "Training model Siamese (no weight sharing and Auxiliary loss):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model Siamese (no weight sharing and Auxiliary loss), the train average error rate is 11.2% and the test average error rate is 15.3%.\n",
      "\n",
      "Training model Siamese (weight sharing):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model Siamese (weight sharing), the train average error rate is 11.7% and the test average error rate is 14.7%.\n",
      "\n",
      "Training model Siamese (weight sharing and Auxiliary Loss):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model Siamese (weight sharing and Auxiliary Loss), the train average error rate is 9.0% and the test average error rate is 10.1%.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(models, model_names, train_data, test_data, batch_size=100, rounds=1, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27365273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fd0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241876\n",
      "241876\n",
      "27828\n",
      "27828\n",
      "14196\n",
      "14196\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2c13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
