{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "constant-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "modified-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = dlc_practical_prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "developing-liberal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weight-sharing \"Siamese\" LeNet\n",
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        \n",
    "        self.LeNet1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),  # 16x10x10 (input is 1x14x14)\n",
    "            nn.MaxPool2d(2),    # 16x5x5\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,2), # 32x4x4\n",
    "            nn.MaxPool2d(2),    # 32x2x2 (-> 1x128 before LeNet2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet2 = nn.Sequential(\n",
    "            nn.Linear(128,64),  # 1x64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),   # 1x32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.LeNet3 = nn.Sequential(\n",
    "            nn.Linear(32,16),   # 1x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16,2)     # 1x2\n",
    "        )\n",
    "        \n",
    "    def forward_bro(self, x):\n",
    "        x = self.LeNet1(x)\n",
    "        x = x.view(-1,1,128)\n",
    "        x = self.LeNet2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.forward_bro(x1)\n",
    "        x2 = self.forward_bro(x2)\n",
    "        x3 = x1 + x2\n",
    "        x3 = self.LeNet3(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "designed-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control convolutions' dimensions\n",
    "x1 = train_input.narrow(0,0,100)\n",
    "x1 = x1[:,0].view(100,1,14,14)\n",
    "weight1 = torch.empty(16,1,5,5).normal_()\n",
    "bias1 = torch.empty(16).normal_()\n",
    "x1 = F.conv2d(x1, weight1, bias1)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "weight2 = torch.empty(32,16,2,2).normal_()\n",
    "bias2 = torch.empty(32).normal_()\n",
    "x1 = F.conv2d(x1, weight2, bias2)\n",
    "\n",
    "x1 = F.max_pool2d(x1, 2)\n",
    "x1 = F.relu(x1)\n",
    "\n",
    "x1 = x1.view(-1,1,128)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dirty-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, batch_size, nb_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            imgs = train_input.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "            loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "            acc_loss += loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "expressed-pizza",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.990972399711609\n",
      "1 6.934654772281647\n",
      "2 6.935028254985809\n",
      "3 6.9333906173706055\n",
      "4 6.9332228899002075\n",
      "5 6.930941700935364\n",
      "6 6.932613790035248\n",
      "7 6.9301891922950745\n",
      "8 6.929503798484802\n",
      "9 6.929929435253143\n",
      "10 6.927061855792999\n",
      "11 6.926907956600189\n",
      "12 6.929477691650391\n",
      "13 6.927361786365509\n",
      "14 6.925181806087494\n",
      "15 6.924086272716522\n",
      "16 6.926539182662964\n",
      "17 6.958846092224121\n",
      "18 6.918391168117523\n",
      "19 6.919260382652283\n",
      "20 6.917004346847534\n",
      "21 6.910929620265961\n",
      "22 6.918404281139374\n",
      "23 6.910204291343689\n",
      "24 6.934026539325714\n",
      "25 6.9286311864852905\n",
      "26 6.916999697685242\n",
      "27 6.920688569545746\n",
      "28 6.906443417072296\n",
      "29 6.925009191036224\n",
      "30 6.888521254062653\n",
      "31 6.860827326774597\n",
      "32 6.86810177564621\n",
      "33 6.887848198413849\n",
      "34 6.879729509353638\n",
      "35 6.892661154270172\n",
      "36 6.869325935840607\n",
      "37 6.893350660800934\n",
      "38 6.831924796104431\n",
      "39 6.863025009632111\n",
      "40 6.880612790584564\n",
      "41 6.831042945384979\n",
      "42 6.823961913585663\n",
      "43 6.848291754722595\n",
      "44 6.7955580949783325\n",
      "45 6.816515803337097\n",
      "46 6.837901949882507\n",
      "47 6.674495577812195\n",
      "48 6.817504048347473\n",
      "49 6.581112384796143\n",
      "50 6.705815553665161\n",
      "51 6.776607692241669\n",
      "52 6.451820552349091\n",
      "53 6.706789195537567\n",
      "54 6.356909215450287\n",
      "55 6.773064434528351\n",
      "56 6.575653910636902\n",
      "57 6.212110340595245\n",
      "58 6.789007902145386\n",
      "59 6.325024247169495\n",
      "60 6.398772180080414\n",
      "61 6.211438357830048\n",
      "62 6.212139248847961\n",
      "63 6.434499800205231\n",
      "64 5.7452352643013\n",
      "65 6.488484501838684\n",
      "66 5.959104776382446\n",
      "67 6.527287840843201\n",
      "68 5.79526299238205\n",
      "69 5.91409370303154\n",
      "70 5.772934198379517\n",
      "71 5.961958229541779\n",
      "72 5.581939339637756\n",
      "73 5.649653971195221\n",
      "74 6.064183384180069\n",
      "75 5.4453994035720825\n",
      "76 5.569523185491562\n",
      "77 5.4811625480651855\n",
      "78 5.761637777090073\n",
      "79 5.840298593044281\n",
      "80 5.098045080900192\n",
      "81 4.7863430082798\n",
      "82 6.44566136598587\n",
      "83 5.253367602825165\n",
      "84 4.74322709441185\n",
      "85 5.757132917642593\n",
      "86 4.989036202430725\n",
      "87 4.334465503692627\n",
      "88 5.14553889632225\n",
      "89 6.390020042657852\n",
      "90 5.610960274934769\n",
      "91 4.395283043384552\n",
      "92 4.412417888641357\n",
      "93 5.169447183609009\n",
      "94 4.605356067419052\n",
      "95 4.080434560775757\n",
      "96 3.2766868472099304\n",
      "97 4.902505099773407\n",
      "98 3.43728044629097\n",
      "99 6.262447893619537\n",
      "100 4.18074905872345\n",
      "101 3.555845707654953\n",
      "102 3.4564598351716995\n",
      "103 5.342793494462967\n",
      "104 3.5489815920591354\n",
      "105 4.146007716655731\n",
      "106 4.773544520139694\n",
      "107 2.7705873996019363\n",
      "108 4.319309681653976\n",
      "109 3.649263232946396\n",
      "110 2.8939240723848343\n",
      "111 5.351153090596199\n",
      "112 3.322217896580696\n",
      "113 2.2220413833856583\n",
      "114 1.1713839396834373\n",
      "115 2.3326207101345062\n",
      "116 5.899528056383133\n",
      "117 3.0120829641819\n",
      "118 3.206053301692009\n",
      "119 5.262298047542572\n",
      "120 2.276878908276558\n",
      "121 1.6921163499355316\n",
      "122 0.9568567723035812\n",
      "123 1.1881745159626007\n",
      "124 0.7750253826379776\n",
      "125 0.4293089061975479\n",
      "126 0.27903142757713795\n",
      "127 0.19762430619448423\n",
      "128 0.15641125664114952\n",
      "129 0.1353277899324894\n",
      "130 0.12033613212406635\n",
      "131 0.10884663835167885\n",
      "132 0.0995838949456811\n",
      "133 0.09192384732887149\n",
      "134 0.08537424122914672\n",
      "135 0.0798669015057385\n",
      "136 0.07466307980939746\n",
      "137 0.07021920243278146\n",
      "138 0.06636604852974415\n",
      "139 0.06289208959788084\n",
      "140 0.05974626634269953\n",
      "141 0.05691550998017192\n",
      "142 0.054291326086968184\n",
      "143 0.051992584485560656\n",
      "144 0.04978945525363088\n",
      "145 0.0478044874034822\n",
      "146 0.04598529962822795\n",
      "147 0.0442434623837471\n",
      "148 0.04268447821959853\n",
      "149 0.04119820729829371\n",
      "150 0.039815946482121944\n",
      "151 0.038550761761143804\n",
      "152 0.03733330382965505\n",
      "153 0.03619421552866697\n",
      "154 0.03512859717011452\n",
      "155 0.03413939522579312\n",
      "156 0.033200267469510436\n",
      "157 0.03229212504811585\n",
      "158 0.031453464180231094\n",
      "159 0.030635868664830923\n",
      "160 0.029870392754673958\n",
      "161 0.029135008109733462\n",
      "162 0.028432643972337246\n",
      "163 0.027785800164565444\n",
      "164 0.027143716579303145\n",
      "165 0.026532843243330717\n",
      "166 0.025970193557441235\n",
      "167 0.02540997345931828\n",
      "168 0.02487423620186746\n",
      "169 0.02437723521143198\n",
      "170 0.02388453367166221\n",
      "171 0.023414218332618475\n",
      "172 0.022973794490098953\n",
      "173 0.02253709454089403\n",
      "174 0.02211928670294583\n",
      "175 0.0217293364694342\n",
      "176 0.02133714617229998\n",
      "177 0.02096263994462788\n",
      "178 0.020604808698408306\n",
      "179 0.02025550731923431\n",
      "180 0.019925143686123192\n",
      "181 0.0195984699530527\n",
      "182 0.019282131223008037\n",
      "183 0.01898120774421841\n",
      "184 0.01868494867812842\n",
      "185 0.018401129287667572\n",
      "186 0.01812379329930991\n",
      "187 0.01785665494389832\n",
      "188 0.017594301723875105\n",
      "189 0.017345262342132628\n",
      "190 0.017096414463594556\n",
      "191 0.01685745012946427\n",
      "192 0.016624658717773855\n",
      "193 0.01640316448174417\n",
      "194 0.016179888043552637\n",
      "195 0.015965486294589937\n",
      "196 0.015757670858874917\n",
      "197 0.015554639394395053\n",
      "198 0.015358063043095171\n",
      "199 0.015162977389991283\n",
      "200 0.014980569365434349\n",
      "201 0.014794515445828438\n",
      "202 0.014613629318773746\n",
      "203 0.014441743027418852\n",
      "204 0.014268828206695616\n",
      "205 0.014103543246164918\n",
      "206 0.013939793454483151\n",
      "207 0.013782215304672718\n",
      "208 0.013625083491206169\n",
      "209 0.01347638398874551\n",
      "210 0.013325016247108579\n",
      "211 0.013180874520912766\n",
      "212 0.013037975411862135\n",
      "213 0.012899930588901043\n",
      "214 0.012762828846462071\n",
      "215 0.012630651122890413\n",
      "216 0.012498954660259187\n",
      "217 0.012371572549454868\n",
      "218 0.01224615250248462\n",
      "219 0.012124103610403836\n",
      "220 0.012003414100036025\n",
      "221 0.01188716827891767\n",
      "222 0.01177033013664186\n",
      "223 0.0116594263818115\n",
      "224 0.011547358706593513\n",
      "225 0.011438145185820758\n",
      "226 0.011331473127938807\n",
      "227 0.011226715869270265\n",
      "228 0.011124961194582283\n",
      "229 0.011022901628166437\n",
      "230 0.010925576440058649\n",
      "231 0.010827197227627039\n",
      "232 0.01073146890848875\n",
      "233 0.010637799801770598\n",
      "234 0.010545853583607823\n",
      "235 0.010455344337970018\n",
      "236 0.010366713628172874\n",
      "237 0.010278617381118238\n",
      "238 0.010193527094088495\n",
      "239 0.01010860176756978\n",
      "240 0.010024927381891757\n",
      "241 0.009944086719769984\n",
      "242 0.009862866252660751\n",
      "243 0.009784769848920405\n",
      "244 0.009706217097118497\n",
      "245 0.009630673157516867\n",
      "246 0.009554582822602242\n",
      "247 0.009479721426032484\n",
      "248 0.009408422105479985\n",
      "249 0.009335503331385553\n"
     ]
    }
   ],
   "source": [
    "model = Siamese()\n",
    "train_model(model, train_input, train_target, 100, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "imposed-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input_data, target_data, batch_size):\n",
    "    nb_errors = 0\n",
    "    \n",
    "    for b in range(0, input_data.size(0), batch_size):\n",
    "            imgs = input_data.narrow(0, b, batch_size)\n",
    "            target = target_data.narrow(0, b, batch_size)\n",
    "            imgs1 = imgs[:,0].view(batch_size, 1, 14, 14)\n",
    "            imgs2 = imgs[:,1].view(batch_size, 1, 14, 14)\n",
    "            output = model(imgs1, imgs2).view(batch_size, -1)\n",
    "            pred = output.max(1)[1]\n",
    "            nb_errors += (pred-target).abs().sum().item()\n",
    "    \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "reliable-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = compute_nb_errors(model, train_input, train_target, 100)\n",
    "test_errors = compute_nb_errors(model, test_input, test_target, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "noticed-jacket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errors/train_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "iraqi-grain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors/test_input.size(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
