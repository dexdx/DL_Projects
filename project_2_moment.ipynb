{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49cc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import empty\n",
    "import math\n",
    "from FC_module import LossMSE, ReLU, Tanh, Sigmoid, FCC, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "test_size = 200\n",
    "valid_size = 100\n",
    "train_input = empty(train_size, 2).uniform_(0,1)\n",
    "train_target = train_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)\n",
    "\n",
    "valid_input = empty(valid_size, 2).uniform_(0,1)\n",
    "valid_target = valid_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)\n",
    "\n",
    "test_input = empty(test_size, 2).uniform_(0,1)\n",
    "test_target = test_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fc110",
   "metadata": {},
   "source": [
    "[Go to Benchamrking](#Benchmarking) with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebbb88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### These two are just for a quick check I know they are terrible :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fcbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_count(pred,true):\n",
    "    pred = (pred > 0.5).long().view(-1)\n",
    "    true = true.long().view(-1)\n",
    "    return (pred.size(0) - (pred-true).abs().sum()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d7398",
   "metadata": {},
   "source": [
    "Temporary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ef293",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = empty(10).uniform_(0,1).expand(5,10)\n",
    "b[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = empty(5,100).fill_(25).mean(dim = 0)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepdim \n",
    "empty(a.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c22780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTrainer(model, num_epoch,train_input,train_target,test_input,test_target, train_batch, test_batch):\n",
    "    \n",
    "    loss_track = []\n",
    "    acc_track = []\n",
    "    test_size = test_input.size(0)\n",
    "    for epoch in range(num_epoch):\n",
    "        minibatch = train_batch\n",
    "        for i in range(0, train_input.size(0), minibatch):\n",
    "            out,loss = model.train(train_input.narrow(0, i, minibatch), train_target.narrow(0, i, minibatch).unsqueeze(1))\n",
    "        if epoch % (num_epoch/10) == 0:\n",
    "            print(\"Loss:\", loss.item())\n",
    "        loss_track.append(loss)\n",
    "        \n",
    "        acc = 0\n",
    "        count = 0\n",
    "        minibatch = test_batch\n",
    "        for i in range(0, test_size, minibatch):\n",
    "            truth = test_target.narrow(0, i, minibatch)\n",
    "            inp = test_input.narrow(0, i, minibatch)\n",
    "            out = model.eval(inp)\n",
    "            #print(out)\n",
    "            acc += accuracy_count(out, truth)\n",
    "        acc_track.append(acc/test_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5a3d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTester(model, test_input,test_target,test_batch):    \n",
    "    acc = 0\n",
    "    count = 0\n",
    "    test_size = test_input.size(0)\n",
    "    minibatch = test_batch\n",
    "    for i in range(0, test_size, minibatch):\n",
    "        truth = test_target.narrow(0, i, minibatch)\n",
    "        inp = test_input.narrow(0, i, minibatch)\n",
    "        out = model.eval(inp)\n",
    "        #print(out)\n",
    "        acc += accuracy_count(out, truth)\n",
    "\n",
    "    return acc/test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182f23d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2296084463596344\n",
      "Loss: 0.21399788558483124\n",
      "Loss: 0.14162799715995789\n",
      "Loss: 0.11288009583950043\n",
      "Loss: 0.10970111936330795\n",
      "Loss: 0.10947927087545395\n",
      "Loss: 0.10960791260004044\n",
      "Loss: 0.10969054698944092\n",
      "Loss: 0.10970363765954971\n",
      "Loss: 0.10966849327087402\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "#torch.set_grad_enabled(False)\n",
    "train_size = 1000\n",
    "test_size = 200\n",
    "valid_size = 100\n",
    "train_input = empty(train_size, 2).uniform_(0,1)\n",
    "train_target = train_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)\n",
    "\n",
    "valid_input = empty(valid_size, 2).uniform_(0,1)\n",
    "valid_target = valid_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)\n",
    "\n",
    "test_input = empty(test_size, 2).uniform_(0,1)\n",
    "test_target = test_input.add(-0.5).pow(2).sum(1).sub(1 / (7)).multiply(-1).sign().add(1).div(2)\n",
    "\n",
    "\n",
    "train_noise = empty(train_size, 2).normal_(0,0.1) \n",
    "valid_noise = empty(valid_size, 2).normal_(0,0.1) \n",
    "test_noise = empty(test_size, 2).normal_(0,0.1)\n",
    "\n",
    "train_input += train_noise\n",
    "valid_input += valid_noise\n",
    "test_input += test_noise\n",
    "\n",
    "\n",
    "seq = Sequential([\"FCC\",\"Tanh\",\"FCC\"],[[2,8],[], [8,1]],\"MSE\",momentum = 0.1)\n",
    "trained_model  = modelTrainer(seq,1000, train_input,train_target,valid_input,valid_target, 20, 10)\n",
    "\n",
    "\n",
    "\n",
    "print(modelTester(trained_model, test_input,test_target,10) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46e76c",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, Tensor, nn\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "def create_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 1),\n",
    "#         nn.ReLU(),\n",
    "    )\n",
    "\n",
    "def train_model(model, train_input, train_target):\n",
    "    loss_track = []\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "    mini_batch = 200\n",
    "    # Iterate through epochs\n",
    "    for i in range(1000):\n",
    "        #Iterate t hrough mini batches\n",
    "        for b in range(0, train_input.size(0), mini_batch):\n",
    "            # Forward pass selecting the corresponding minibacth\n",
    "            output = model(train_input.narrow(0, b, mini_batch))\n",
    "            # Calculate loss\n",
    "            loss = loss_func(output.squeeze(), train_target.narrow(0, b, mini_batch))\n",
    "#             print(\"Loss:\", loss.item())\n",
    "            # Reset zero grad\n",
    "            model.zero_grad()\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            #Update step\n",
    "            optimizer.step()\n",
    "        loss_track.append(loss)\n",
    "    plt.plot(loss_track)\n",
    "    \n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "        output = model(data_input)\n",
    "        comp = output.argmax(dim = 1) != data_target.argmax(dim = 1)\n",
    "        nb_errors = torch.where(comp)[0].size()[0]\n",
    "        error_rate = nb_errors/data_input.size(0)\n",
    "        print(f'There were a total of {nb_errors} errors, or {error_rate} of the testing set.')\n",
    "        \n",
    "        \n",
    "model = create_model()\n",
    "train_model(model, train_input, train_target)\n",
    "# compute_nb_errors(model, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf556c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
